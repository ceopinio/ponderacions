---
title: "Ponderacions dels estudis"
output: html_notebook
---

## 0.1. Càrrega llibreries

```{r carrega llibreries, message=FALSE, warning=FALSE}
library(pacman)
library(tidyverse)

p_load(yaml, # Paquets a utilitzar
       haven,
       devtools,
       pewmethods,
       mice,
       survey)

```

## 0.2. Càrrega configuració

```{r carrega config, message=FALSE, warning=FALSE}
list2env(read_yaml("config/config_jardiaca.yaml"), envir=globalenv())
source("R/obtenir_dist.R")
```

## 1. Càrrega dades

```{r carrega dades, message=FALSE, warning=FALSE}
## Microdades original ---------------------------
dades_onada_2 <- CEOdata::CEOdata(reo = "1118", raw = TRUE)

dades_longi <- haven::read_sav("microdades_anonimitzades_longitudinal.sav")

## Dades poblacionals ---------------------------
poblacio_dist <- read_delim(file.path(RUTA_INDICADORS, "poblacio.csv"), 
                            delim = ";", escape_double = FALSE, locale = locale(decimal_mark = ","), 
                            trim_ws = TRUE)
```

# 2. PONDERACIONS DE NO-RESPOSTA LONGITUDINAL

Elaborem les ponderacions que ajusten les diferències determinades per l'attrition (la no-resposta entre les persones que ja formen part del Panel del CEO) en l'enquesta longitudinal

## 2.1. Neteja de les dades

Per construir els models, necessitem tenir les dades de l'onada 1, juntament amb una variable dicotòmica que indiqui si l'enquestat ha participat en l'onada 2. Les variables que emprarem en la modelització també les hem de tenir en el format adequat.

```{r 2_1_neteja_dades}
dades_onada_1 <- dades_longi |> 
  filter(ONADA == 1) |> 
  mutate(resposta_w2 = ifelse(ID_ANONIM %in% dades_onada_2$ID_ANONIM, 1, 0)) |> 
  mutate(across(c(SEXE, EDAT_CEO, LLOC_NAIX, LLENGUA_PRIMERA_1_3, CLUSTER21, SENTIMENT_PERTINENCA, MODE_ADMIN),
                ~ haven::as_factor(.))) |> 
  mutate(
    ESTUDIS = case_when(ESTUDIS_1_6 == 1 ~ "Primaris",
                        ESTUDIS_1_6 <= 4 ~ "Secundaris",
                        ESTUDIS_1_6 <= 6 ~ "Superiors",
                        ESTUDIS_1_6 == 7777 ~ "Valor perdut",
                        TRUE ~ "Valor perdut"),
    ESTUDIS = as.factor(ESTUDIS)
  ) |> 
  mutate(SIMPATIA = case_when(
    SIMPATIA_PARTIT %in% c(2, 7, 19, 20, 80) ~ "Altres",
    SIMPATIA_PARTIT %in% c(98, 7777, 9999) ~ "NSNC",
    SIMPATIA_PARTIT == 1 ~ "PP",
    SIMPATIA_PARTIT == 3 ~ "ERC",
    SIMPATIA_PARTIT == 4 ~ "PSC",
    SIMPATIA_PARTIT == 6 ~ "Cs",
    SIMPATIA_PARTIT == 10 ~ "CUP",
    SIMPATIA_PARTIT == 21 ~ "JxCat",
    SIMPATIA_PARTIT == 23 ~ "VOX",
    SIMPATIA_PARTIT %in% c(18, 24) ~ "Comuns Sumar",
    SIMPATIA_PARTIT == 95 ~ "Cap"
  )) |> 
  mutate(IDEOLOGIA = case_when(
    IDEOL_0_10 %in% c(0, 2) ~ "Extrema esquerra (0-2)",
    IDEOL_0_10 %in% c(3, 4) ~ "Esquerra (3-4)",
    IDEOL_0_10 == 5 ~ "Centre (5)",
    IDEOL_0_10 %in% c(6, 7) ~ "Dreta (6-7)",
    IDEOL_0_10 %in% c(8, 10) ~ "Extrema dreta (8-10)",
    TRUE ~ "NSNC"
  )) |> 
  mutate(INTERES_POL = case_when(
    INTERES_POL_0_10 %in% c(0, 1, 2) ~ "Gens interessat (0-2)",
    INTERES_POL_0_10 %in% c(3, 4, 5) ~ "Poc interessat (3-5)",
    INTERES_POL_0_10 %in% c(6, 7, 8) ~ "Interessat (6-8)",
    INTERES_POL_0_10 %in% c(9, 10) ~ "Molt interessat (9-10)",
    TRUE ~ "NSNC"
  )) |> 
  mutate(across(c(INTERES_POL, IDEOLOGIA, SIMPATIA), ~ as.factor(.)))
```

## 2.2. Modelització de la no-resposta

Utilitzem un model de regressió logística per determinar la probabilitat de contestar a la segona onada per cadascun dels enquestats de la primera onada. Hi afegim:
1. Informació de sociodemogràfiques bàsiques
2. Informació d'actituds polítiques bàsiques
3. Informació de comportament de l'enquestat en el Panel (contesta online o en paper)

```{r 2_2_modelitzacio}
attrition_model <- glm(resposta_w2 ~ SEXE + EDAT_CEO + LLOC_NAIX + LLENGUA_PRIMERA_1_3 + ESTUDIS + CLUSTER21 +
                         INTERES_POL + IDEOLOGIA + SENTIMENT_PERTINENCA + SIMPATIA + MODE_ADMIN,
                       data = dades_onada_1,
                       family = "binomial")
```

## 2.3. Ponderacions de no-resposta

```{r calcular_ipw}
# 1. Calculem les probabilitats predites pel model
dades_onada_1$prob_resposta <- predict(attrition_model, type = "response")

# 2. Creem les IPW ("Inverse Probability Weights")
dades_onada_1$ipw <- 1 / dades_onada_1$prob_resposta

# 3. Normalitzem els pesos (per a que tinguin mitjana 1)
dades_onada_1$ipw <- dades_onada_1$ipw / mean(dades_onada_1$ipw)
```


# 3. PONDERACIONS DE POST-ESTRATIFICACIÓ

## 3.1. Selecció de les variables necessàries per les ponderacions post-estratificació

Seleccionem les variables següents 
- SEXE i EDAT_GR (ponderem amb la combinació d'ambdues) 
- LLOC_NAIX 
- LLENGUA_PRIMERA_1_3 
- ESTUDIS_1_6 
- CLUSTER21

```{r dades ponderacions, message=FALSE, warning=FALSE}
dades_raking <- dades_onada_2 |> 
  dplyr::select(IDENTIFICADOR_COMPLET, MODE_ADMIN, SEXE, EDAT_GR, LLOC_NAIX, LLENGUA_PRIMERA_1_3, ESTUDIS_1_6, CLUSTER21, HABITAT, PROVINCIA)
```

## 3.2. Afegim les ponderacions de no-resposta longitudinal

Per a les persones que no tenen una ponderació de no-resposta longitudinal (perquè són noves en la segona onada), els pesos són 1.

```{r}
dades_raking <- dades_raking |> 
  left_join(dades_onada_1 |> select(IDENTIFICADOR_COMPLET, ipw), by = "IDENTIFICADOR_COMPLET") |> 
  mutate(ipw = ifelse(is.na(ipw), 1, ipw))
```


## 3.3. Neteja dades poblacionals

Ens quedem amb les dades poblacionals de referència pel nostre marc mostral (residents de 16 anys i més) més recents

```{r neteja poblacionals, message=FALSE, warning=FALSE}
poblacio_dist <- poblacio_dist |> 
  group_by(identificador, codi_resposta) |>
  filter(any == max(any)) |>
  ungroup() |>
  # Indiquem les dades poblacionals de referència (residents de 16 anys o més)
  rename(valor = res_16, # Opcions: res_16, res_18, esp_15, esp_18
         resposta = resposta_16) |> # Opcions: resposta_16, resposta_18
  select(identificador_svy, codi_resposta, valor, resposta) |>
  rename(identificador = identificador_svy)
```

## 3.4. Neteja de les dades

Abans de calcular les ponderacions, treiem els valors de la mostra que no hi són a la població i els passem a NA.

```{r neteja dades, message=FALSE, warning=FALSE}
dades_raking <- dades_raking |> 
  # SEXE i EDAT_GR -------------------------------------------------
  group_by(SEXE, EDAT_GR) |> 
  mutate(
    SEXE_EDAT_SVY = case_when(EDAT_GR < 100 & EDAT_GR != 99 & SEXE == 1 ~ paste0(SEXE, EDAT_GR),
                              EDAT_GR < 100 & EDAT_GR != 99 & SEXE == 2 ~ paste0("6", EDAT_GR),
                              TRUE ~ NA_character_),
    SEXE_EDAT_SVY = as.factor(SEXE_EDAT_SVY)
  ) |> 
  ungroup() |>
  # LLOC_NAIX -------------------------------------------------
  mutate(
    LLOC_NAIX_SVY = as.factor(ifelse(LLOC_NAIX %in% c(1, 2, 5), LLOC_NAIX, NA))
  ) |>
  # LLENGUA_PRIMERA -------------------------------------------------
  mutate(
    LLENGUA_PRIMERA_SVY = as.factor(ifelse(LLENGUA_PRIMERA_1_3 %in% c(1, 2, 80), LLENGUA_PRIMERA_1_3, NA))
  ) |>
  # ESTUDIS -------------------------------------------------
  mutate(
    ESTUDIS_SVY = case_when( ESTUDIS_1_6 == 1 ~ 1,
                             ESTUDIS_1_6 <= 4 ~ 2,
                             ESTUDIS_1_6 <= 6 ~ 3,
                             ESTUDIS_1_6 == 7777 ~ NA_real_,
                             TRUE ~ NA_real_),
    ESTUDIS_SVY = as.factor(ESTUDIS_SVY),
  ) |>
  # CLUSTER21 -------------------------------------------------
 mutate(
    CLUSTER21_SVY = as.factor( ifelse(CLUSTER21 %in% c(1:6), CLUSTER21, NA) )
  )
```

## 3.5. Imputem NA

En algunes variables que s'usen per la ponderació hi ha valors faltants, per tant, es du a terme una imputació d'aquests. Per a fer-ho s'usa la funció `impute_vars` del paquet [pewmethods](https://github.com/pewresearch/pewmethods), que es basa en una imputació *Random Forest* a partir de les variables que tenen més relació amb les que tenen valors faltants.

```{r imputation}
colSums(is.na(dades_raking))

dades_imputed <- dades_raking |> 
    select(-IDENTIFICADOR_COMPLET, -MODE_ADMIN) |>
    impute_vars(to_impute = c("SEXE_EDAT_SVY", "LLOC_NAIX_SVY", "LLENGUA_PRIMERA_SVY", "ESTUDIS_SVY", "CLUSTER21_SVY", "HABITAT", "PROVINCIA"), seed = 852)

colSums(is.na(dades_imputed))
```

## 3.6. Obtenció de les dades poblacionals

A partir de les dades poblacionals, es calcula la freqüència poblacional a partir dels individus de la mostra. Aquest càlcul es fa per a totes les variables que s'escullen per a pondera-les, ja que l'algorisme que s'usa necessita aquesta informació.

```{r data_target}
# SEXE i EDAT_GR -------------------------------------------------
sexe_edat_dist <- obtenir_dist("SEXE_EDAT_SVY", dades_imputed, poblacio_dist)

# LLOC_NAIX -------------------------------------------------
lloc_naix_dist <- obtenir_dist("LLOC_NAIX_SVY", dades_imputed, poblacio_dist)
  
# LLENGUA_PRIMERA -------------------------------------------------
llengua_primera_dist <- obtenir_dist("LLENGUA_PRIMERA_SVY", dades_imputed, poblacio_dist)

# ESTUDIS -------------------------------------------------
estudis_dist <- obtenir_dist("ESTUDIS_SVY", dades_imputed, poblacio_dist)

# CLUSTER21 -------------------------------------------------
cluster_dist <- obtenir_dist("CLUSTER21_SVY", dades_imputed, poblacio_dist)
```

## 3.7. Raking

Fem la ponderació mitjançant algoritme de raking. Aquest algoritme ajusta els pesos de la mostra perquè coincideixin amb les freqüències poblacionals de les variables seleccionades.
Retallem les ponderacions per dalt i per baix per evitar que siguin massa extremes (trimming).

```{r raking}
# Creem les dades d'enquestes (amb la ponderació de no-resposta longitudinal) i assignant un mostreig aleatori simple
dades_svy <- svydesign(ids = ~ 1,
                       weights = ~ipw,
                       data = dades_imputed)

# Ponderem 
sample_margins <- list(~SEXE_EDAT_SVY, ~LLOC_NAIX_SVY,  ~LLENGUA_PRIMERA_SVY, ~ESTUDIS_SVY, ~CLUSTER21_SVY)
population_margins <- list(sexe_edat_dist, lloc_naix_dist, llengua_primera_dist, estudis_dist, cluster_dist)

dades_svy_rake <- rake(design = dades_svy,
                       sample.margins = sample_margins,
                       population.margins = population_margins)

## Eliminació de pesos extrems (trimming) ----------------------------------------
dades_svy_rake_trim10 <- trimWeights(dades_svy_rake,
                                     lower = 0.1,
                                     upper = 10,
                                     strict = TRUE) 


summary(weights(dades_svy_rake))
summary(weights(dades_svy_rake_trim10))
```

## 3.8. Diagnosi

Obtenim diferents mètriques de diagnosi de les ponderacions.

```{r diagnosi}
# Obtenir l'aproximació de Kish
# Obtenim l'efecte del disseny, efecte de la mida de la mostra i l'error d'estimació
calculate_deff(weights(dades_svy_rake_trim10))
```

## 3.9. Guardar resultats

Creem la variable de ponderació i en guardem els resultats.

```{r save results}
## Creem nova variable en les dades definitives ----------------------------------------
dades_raking$PONDERA <- weights(dades_svy_rake_trim10)

## Fem que la mitjana sumi exactament 1
dades_raking$PONDERA <- dades_raking$PONDERA / mean(dades_raking$PONDERA)
```

```{r save .sav results}
## Guardem la matriu .sav ----------------------------------------
write_sav(dades_raking, file.path(DTA_FOLDER, "PONDERA_longi_v2.sav"))
```
